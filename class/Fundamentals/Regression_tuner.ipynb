{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f310246",
   "metadata": {},
   "source": [
    "It is highly recommended to use a powerful **GPU**, you can use it for free uploading this notebook to [Google Colab](https://colab.research.google.com/notebooks/intro.ipynb).\n",
    "<table align=\"center\">\n",
    " <td align=\"center\"><a target=\"_blank\" href=\"https://colab.research.google.com/github/ezponda/intro_deep_learning/blob/main/class/Fundamentals/Regression_tuner.ipynb\">\n",
    "        <img src=\"https://colab.research.google.com/img/colab_favicon_256px.png\"  width=\"50\" height=\"50\" style=\"padding-bottom:5px;\" />Run in Google Colab</a></td>\n",
    "  <td align=\"center\"><a target=\"_blank\" href=\"https://github.com/ezponda/intro_deep_learning/blob/main/class/Fundamentals/Regression_tuner.ipynb\">\n",
    "        <img src=\"https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png\"  width=\"50\" height=\"50\" style=\"padding-bottom:5px;\" />View Source on GitHub</a></td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2360c95e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-09 16:31:45.698234: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-09 16:31:45.899524: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-09 16:31:46.067405: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1746801106.218565    2578 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1746801106.260510    2578 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1746801106.590993    2578 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746801106.591070    2578 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746801106.591074    2578 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1746801106.591076    2578 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-09 16:31:46.626917: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "tf.keras.utils.set_random_seed(0) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45e3013",
   "metadata": {},
   "source": [
    "# Abalone Dataset\n",
    "\n",
    "Abalones are marine snails that can be found along coasts of almost every continent. \n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/0/0b/AbaloneInside.jpg/440px-AbaloneInside.jpg\" alt=\"abalone\" border=\"0\" width=\"400\" height=\"500\">\n",
    "\n",
    "\n",
    "\n",
    "In this notebook we are going to Predict the age of abalone from physical measurements. [Link to documentation](https://archive.ics.uci.edu/ml/datasets/abalone)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "801c6c84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.435</td>\n",
       "      <td>0.335</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.334</td>\n",
       "      <td>0.1355</td>\n",
       "      <td>0.0775</td>\n",
       "      <td>0.0965</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.585</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.3545</td>\n",
       "      <td>0.2075</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.655</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.160</td>\n",
       "      <td>1.092</td>\n",
       "      <td>0.3960</td>\n",
       "      <td>0.2825</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.545</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.2940</td>\n",
       "      <td>0.1495</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.545</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.3740</td>\n",
       "      <td>0.1695</td>\n",
       "      <td>0.2300</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Length  Diameter  Height  Whole weight  Shucked weight  Viscera weight  \\\n",
       "0   0.435     0.335   0.110         0.334          0.1355          0.0775   \n",
       "1   0.585     0.450   0.125         0.874          0.3545          0.2075   \n",
       "2   0.655     0.510   0.160         1.092          0.3960          0.2825   \n",
       "3   0.545     0.425   0.125         0.768          0.2940          0.1495   \n",
       "4   0.545     0.420   0.130         0.879          0.3740          0.1695   \n",
       "\n",
       "   Shell weight  Age  \n",
       "0        0.0965    7  \n",
       "1        0.2250    6  \n",
       "2        0.3700   14  \n",
       "3        0.2600   16  \n",
       "4        0.2300   13  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\n",
    "    \"https://storage.googleapis.com/download.tensorflow.org/data/abalone_train.csv\",\n",
    "    names=[\"Length\", \"Diameter\", \"Height\", \"Whole weight\", \"Shucked weight\",\n",
    "           \"Viscera weight\", \"Shell weight\", \"Age\"])\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9edcad0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3320.000000</td>\n",
       "      <td>3320.000000</td>\n",
       "      <td>3320.000000</td>\n",
       "      <td>3320.000000</td>\n",
       "      <td>3320.000000</td>\n",
       "      <td>3320.000000</td>\n",
       "      <td>3320.000000</td>\n",
       "      <td>3320.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.522693</td>\n",
       "      <td>0.406575</td>\n",
       "      <td>0.139271</td>\n",
       "      <td>0.824734</td>\n",
       "      <td>0.357705</td>\n",
       "      <td>0.180162</td>\n",
       "      <td>0.237921</td>\n",
       "      <td>9.896988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.121164</td>\n",
       "      <td>0.100120</td>\n",
       "      <td>0.042708</td>\n",
       "      <td>0.491182</td>\n",
       "      <td>0.222223</td>\n",
       "      <td>0.110182</td>\n",
       "      <td>0.140261</td>\n",
       "      <td>3.205654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.345000</td>\n",
       "      <td>0.115000</td>\n",
       "      <td>0.436375</td>\n",
       "      <td>0.181500</td>\n",
       "      <td>0.092000</td>\n",
       "      <td>0.127375</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.425000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.795250</td>\n",
       "      <td>0.335500</td>\n",
       "      <td>0.170750</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.615000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.165000</td>\n",
       "      <td>1.150000</td>\n",
       "      <td>0.504500</td>\n",
       "      <td>0.253125</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.815000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>1.130000</td>\n",
       "      <td>2.825500</td>\n",
       "      <td>1.488000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>1.005000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Length     Diameter       Height  Whole weight  Shucked weight  \\\n",
       "count  3320.000000  3320.000000  3320.000000   3320.000000     3320.000000   \n",
       "mean      0.522693     0.406575     0.139271      0.824734        0.357705   \n",
       "std       0.121164     0.100120     0.042708      0.491182        0.222223   \n",
       "min       0.075000     0.055000     0.000000      0.002000        0.001000   \n",
       "25%       0.450000     0.345000     0.115000      0.436375        0.181500   \n",
       "50%       0.540000     0.425000     0.140000      0.795250        0.335500   \n",
       "75%       0.615000     0.480000     0.165000      1.150000        0.504500   \n",
       "max       0.815000     0.650000     1.130000      2.825500        1.488000   \n",
       "\n",
       "       Viscera weight  Shell weight          Age  \n",
       "count     3320.000000   3320.000000  3320.000000  \n",
       "mean         0.180162      0.237921     9.896988  \n",
       "std          0.110182      0.140261     3.205654  \n",
       "min          0.000500      0.001500     1.000000  \n",
       "25%          0.092000      0.127375     8.000000  \n",
       "50%          0.170750      0.230000     9.000000  \n",
       "75%          0.253125      0.325000    11.000000  \n",
       "max          0.760000      1.005000    27.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c554e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train.pop('Age')\n",
    "X_train = df_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fede61bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\n",
    "    \"https://storage.googleapis.com/download.tensorflow.org/data/abalone_test.csv\",\n",
    "    names=[\"Length\", \"Diameter\", \"Height\", \"Whole weight\", \"Shucked weight\",\n",
    "           \"Viscera weight\", \"Shell weight\", \"Age\"])\n",
    "y_test = df_test.pop('Age')\n",
    "X_test = df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de841977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (3320, 7), X_test shape: (850, 7)\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train shape: {X_train.shape}, X_test shape: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1bf8de",
   "metadata": {},
   "source": [
    "## Regression Losses\n",
    "\n",
    "- **Mean Squared Error (MSE)**: \n",
    "\n",
    "```python\n",
    "tf.keras.losses.MSE\n",
    "```\n",
    "```python\n",
    "model.compile(loss='mse') or model.compile(loss=tf.keras.losses.MSE)\n",
    "```\n",
    "\n",
    "$$ \\mathrm{MSE} = \\frac{\\sum_{i=1}^n\\left( y_i - \\hat{y_i}\\right)^2}{n}$$\n",
    "\n",
    "\n",
    "- **Mean Absolute Error (MAE)**: \n",
    "\n",
    "```python\n",
    "tf.keras.losses.MAE\n",
    "```\n",
    "```python\n",
    "model.compile(loss='mae') or model.compile(loss=tf.keras.losses.MAE)\n",
    "```\n",
    "\n",
    "$$ \\mathrm{MAE} = \\frac{\\sum_{i=1}^n\\left| y_i - \\hat{y_i}\\right|}{n}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313693e1",
   "metadata": {},
   "source": [
    "## Question 1: Create a net with at least 1 hidden layer\n",
    "\n",
    "\n",
    "1. You can use the [Functional API](https://keras.io/guides/functional_api/):\n",
    "\n",
    "You need to start with an input data entry:\n",
    "```python    \n",
    "    inputs = keras.Input(shape=(...,))\n",
    "    layer_1 = layers.Dense(...)(inputs)\n",
    "```\n",
    "\n",
    "and the network outputs:\n",
    "```python\n",
    "outputs = layers.Dense(...)(previous_layer)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "```\n",
    "\n",
    "2. Or you can use [Sequential API](https://keras.io/guides/sequential_model/)\n",
    "\n",
    "```python\n",
    "model = keras.Sequential(name='example_model')\n",
    "model.add(layers.Dense(..., input_shape=(8,))\n",
    "model.add(...\n",
    "```\n",
    "\n",
    "You can introduce regularization methods seen in [Prevent_Overfitting.ipynb](https://github.com/ezponda/intro_deep_learning/blob/main/class/Fundamentals/Prevent_Overfitting.ipynb) like [Dropout layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout):\n",
    "\n",
    "\n",
    "```python\n",
    "tf.keras.layers.Dropout(\n",
    "    rate, noise_shape=None, seed=None, **kwargs\n",
    ")\n",
    "```\n",
    "\n",
    "With Functional API:\n",
    "```python\n",
    "next_layer = layers.Dropout(0.4)(prev_layer)\n",
    "```\n",
    "With Sequential:\n",
    "```python\n",
    "model.add(layers.Dropout(0.4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f142132",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manu24/miniconda3/envs/demo-env/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m288\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,056\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m1,056\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,433</span> (9.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,433\u001b[0m (9.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,433</span> (9.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,433\u001b[0m (9.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "model.add(layers.Dense(32, input_shape=(8,), activation='relu'))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "# output layer\n",
    "model.add(layers.Dense(1, activation='relu'))\n",
    "\n",
    "\n",
    "## model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2b73b78f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_7 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m65,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m257\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">68,097</span> (266.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m68,097\u001b[0m (266.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">68,097</span> (266.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m68,097\u001b[0m (266.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Using the Functional API\n",
    "# 1. Define the input layer\n",
    "inputs = keras.Input(shape=(7,))\n",
    "\n",
    "# 2. Build the hidden layers, You can also add dropout or other layer types\n",
    "x = layers.Dense(256, activation='relu')(inputs)\n",
    "\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(256, activation='relu')(x)\n",
    "\n",
    "# 3. Define the output layer\n",
    "outputs = layers.Dense(1, activation='linear')(x)\n",
    "\n",
    "# 4. Create the model by specifying inputs and outputs\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name='functional_model')\n",
    "\n",
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3ceb6dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping callback\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=0.5,\n",
    "    min_delta=0.001,\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "26bb1a7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 54.1808 - mae: 6.2689 - mse: 54.1808 - val_loss: 7.6276 - val_mae: 1.9659 - val_mse: 7.6276\n",
      "Epoch 2/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 7.2919 - mae: 1.9624 - mse: 7.2919 - val_loss: 6.7574 - val_mae: 1.8268 - val_mse: 6.7574\n",
      "Epoch 3/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.9066 - mae: 1.9142 - mse: 6.9066 - val_loss: 6.3011 - val_mae: 1.7793 - val_mse: 6.3011\n",
      "Epoch 4/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.5152 - mae: 1.8546 - mse: 6.5152 - val_loss: 6.1189 - val_mae: 1.7055 - val_mse: 6.1189\n",
      "Epoch 5/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 6.1766 - mae: 1.7962 - mse: 6.1766 - val_loss: 5.6201 - val_mae: 1.6768 - val_mse: 5.6201\n",
      "Epoch 6/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.9561 - mae: 1.7775 - mse: 5.9561 - val_loss: 5.4583 - val_mae: 1.6363 - val_mse: 5.4583\n",
      "Epoch 7/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.5519 - mae: 1.7374 - mse: 5.5519 - val_loss: 5.1530 - val_mae: 1.6403 - val_mse: 5.1530\n",
      "Epoch 8/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.7699 - mae: 1.7706 - mse: 5.7699 - val_loss: 5.0429 - val_mae: 1.6031 - val_mse: 5.0429\n",
      "Epoch 9/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.3010 - mae: 1.6913 - mse: 5.3010 - val_loss: 4.9333 - val_mae: 1.6358 - val_mse: 4.9333\n",
      "Epoch 10/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.5648 - mae: 1.7428 - mse: 5.5648 - val_loss: 4.8727 - val_mae: 1.6242 - val_mse: 4.8727\n",
      "Epoch 11/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.1720 - mae: 1.6827 - mse: 5.1720 - val_loss: 4.8070 - val_mae: 1.6227 - val_mse: 4.8070\n",
      "Epoch 12/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.0444 - mae: 1.6315 - mse: 5.0444 - val_loss: 4.7667 - val_mae: 1.5941 - val_mse: 4.7667\n",
      "Epoch 13/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.1515 - mae: 1.6875 - mse: 5.1515 - val_loss: 4.7592 - val_mae: 1.5890 - val_mse: 4.7592\n",
      "Epoch 14/50\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.1481 - mae: 1.6889 - mse: 5.1481 - val_loss: 4.8078 - val_mae: 1.6437 - val_mse: 4.8078\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=['mae', 'mse'],\n",
    ")\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=50,\n",
    "    validation_split=0.2,\n",
    "    batch_size=32,\n",
    "    callbacks=early_stopping,  # early stopping\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "644f80fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m27/27\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.9385 - mae: 1.7011 - mse: 5.9385 \n",
      "Test Loss: 5.358916759490967\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test Loss: {}'.format(results[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c909754",
   "metadata": {},
   "source": [
    "## Question 2: Normalize the inputs and train the same model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9ed6000",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ellipsis' object has no attribute 'mean'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m X_train_norm \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m      4\u001b[0m X_test_norm \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX_train mu, sigma\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[43mX_train_norm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m(\u001b[38;5;241m0\u001b[39m), X_train_norm\u001b[38;5;241m.\u001b[39mstd(\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX_test mu, sigma\u001b[39m\u001b[38;5;124m'\u001b[39m, X_test_norm\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m0\u001b[39m), X_test_norm\u001b[38;5;241m.\u001b[39mstd(\u001b[38;5;241m0\u001b[39m))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ellipsis' object has no attribute 'mean'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_norm = ...\n",
    "X_test_norm = ...\n",
    "print('X_train mu, sigma', X_train_norm.mean(0), X_train_norm.std(0))\n",
    "print('X_test mu, sigma', X_test_norm.mean(0), X_test_norm.std(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16ac44c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "...\n",
    "## model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b1d2308",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "bad operand type for abs(): 'ellipsis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Early stopping callback\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m \u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEarlyStopping\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_delta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrestore_best_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/demo-env/lib/python3.12/site-packages/keras/src/callbacks/early_stopping.py:85\u001b[0m, in \u001b[0;36mEarlyStopping.__init__\u001b[0;34m(self, monitor, min_delta, patience, verbose, mode, baseline, restore_best_weights, start_from_epoch)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m=\u001b[39m verbose\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbaseline \u001b[38;5;241m=\u001b[39m baseline\n\u001b[0;32m---> 85\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_delta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mabs\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmin_delta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwait \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstopped_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: bad operand type for abs(): 'ellipsis'"
     ]
    }
   ],
   "source": [
    "# Early stopping callback\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor=...,\n",
    "    patience=...,\n",
    "    min_delta=...,\n",
    "    restore_best_weights=...,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "173bef88",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Argument `validation_split` is only supported for tensors or NumPy arrays.Found incompatible type in the input: [<class 'ellipsis'>]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m      2\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      3\u001b[0m     loss\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mMSE,\n\u001b[1;32m      4\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmae\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      5\u001b[0m )\n\u001b[0;32m----> 7\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# early stoppings\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/demo-env/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/demo-env/lib/python3.12/site-packages/keras/src/trainers/data_adapters/array_slicing.py:480\u001b[0m, in \u001b[0;36mtrain_validation_split\u001b[0;34m(arrays, validation_split)\u001b[0m\n\u001b[1;32m    478\u001b[0m unsplitable \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mtype\u001b[39m(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m flat_arrays \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m can_slice_array(t)]\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m unsplitable:\n\u001b[0;32m--> 480\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    481\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgument `validation_split` is only supported \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    482\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor tensors or NumPy arrays.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    483\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound incompatible type in the input: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00munsplitable\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    484\u001b[0m     )\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(t \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m flat_arrays):\n\u001b[1;32m    487\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arrays, arrays\n",
      "\u001b[0;31mValueError\u001b[0m: Argument `validation_split` is only supported for tensors or NumPy arrays.Found incompatible type in the input: [<class 'ellipsis'>]"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.keras.losses.MSE,\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train_norm,\n",
    "    y_train,\n",
    "    epochs=50,\n",
    "    validation_split=0.2,\n",
    "    batch_size=32,\n",
    "    callbacks=...,  # early stoppings\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6040ce5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unrecognized data type: x=Ellipsis (of type <class 'ellipsis'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest Loss: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(results[\u001b[38;5;241m0\u001b[39m]))\n",
      "File \u001b[0;32m~/miniconda3/envs/demo-env/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/demo-env/lib/python3.12/site-packages/keras/src/trainers/data_adapters/__init__.py:125\u001b[0m, in \u001b[0;36mget_data_adapter\u001b[0;34m(x, y, sample_weight, batch_size, steps_per_epoch, shuffle, class_weight)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m GeneratorDataAdapter(x)\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# TODO: should we warn or not?\u001b[39;00m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;66;03m# warnings.warn(\u001b[39;00m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m#     \"`shuffle=True` was passed, but will be ignored since the \"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized data type: x=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(x)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Unrecognized data type: x=Ellipsis (of type <class 'ellipsis'>)"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test_norm, y_test, verbose=1)\n",
    "print('Test Loss: {}'.format(results[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de862aa9",
   "metadata": {},
   "source": [
    "## Optimizers:\n",
    "\n",
    "- [SGD](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/SGD): Gradient descent with momentum\n",
    "```python\n",
    "tf.keras.optimizers.SGD(\n",
    "    learning_rate=0.01, momentum=0.0, nesterov=False, name='SGD', **kwargs\n",
    ")\n",
    "```\n",
    "If momentum is 0:\n",
    "```python\n",
    "w = w - learning_rate * gradient\n",
    "```\n",
    "If we have momentum:\n",
    " \n",
    " ```python\n",
    "velocity = momentum * velocity - learning_rate * g\n",
    "w = w + velocity\n",
    "```\n",
    "\n",
    "\n",
    "- [RMSprop](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/RMSprop): Root Mean Square Propagation\n",
    "```python\n",
    "tf.keras.optimizers.RMSprop(\n",
    "    learning_rate=0.001, rho=0.9, momentum=0.0, epsilon=1e-07, centered=False,\n",
    "    name='RMSprop', **kwargs\n",
    ")\n",
    "```\n",
    "- [Adam](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam): Adaptive Moment Estimation,  is an update to the RMSProp algorithm\n",
    "```python\n",
    "tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False,\n",
    "    name='Adam', **kwargs\n",
    ")\n",
    "```\n",
    "\n",
    "```python\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(learning_rate=0.001))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d744232",
   "metadata": {},
   "source": [
    "## Question 3: Train the same model with different optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c797bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "...\n",
    "## model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81ef1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=...,\n",
    "    loss=...,\n",
    "    metrics=[...]\n",
    ")\n",
    "model.fit(X_train_norm, y_train, epochs=50, validation_split=0.2, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36eaf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(X_test_norm, y_test, verbose=1)\n",
    "print('Test Loss: {}'.format(results[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2377a7ff",
   "metadata": {},
   "source": [
    "# Keras Tuner : Introduction to Hyperparameter Optimization\n",
    "\n",
    "The [Keras Tuner](https://www.tensorflow.org/tutorials/keras/keras_tuner) is a library for hyper-parameter tuning.\n",
    "\n",
    "## What is Hyperparameter Tuning?\n",
    "\n",
    "Hyperparameter tuning is the process of finding the optimal set of hyperparameters for a machine learning model to maximize its performance. Unlike model parameters (weights and biases) that are learned during training, hyperparameters are set before the learning process begins and influence how the model learns.\n",
    "\n",
    "Common hyperparameters include:\n",
    "- **Model architecture**: number of layers, units per layer\n",
    "- **Training parameters**: learning rate, batch size, dropout rate\n",
    "- **Regularization**: L1/L2 penalties, early stopping criteria\n",
    "\n",
    "Manual tuning of these parameters can be time-consuming and often leads to suboptimal results. Keras Tuner provides an automated approach to efficiently search the hyperparameter space.\n",
    "\n",
    "## Understanding Different Tuning Strategies\n",
    "\n",
    "Keras Tuner offers four main strategies for hyperparameter optimization:\n",
    "\n",
    "### 1. RandomSearch\n",
    "- **How it works**: Randomly samples from the hyperparameter space\n",
    "- **Pros**: Simple, easily parallelizable, no assumptions about parameter importance\n",
    "- **Cons**: Can be inefficient for large search spaces\n",
    "- **Best for**: Initial exploration or when little is known about the hyperparameter landscape\n",
    "\n",
    "### 2. Hyperband\n",
    "- **How it works**: Allocates resources (epochs) dynamically, quickly discarding poor performers\n",
    "- **Pros**: More efficient than random search, especially for deep networks\n",
    "- **Cons**: More complex to configure correctly\n",
    "- **Best for**: When training is computationally expensive and you want to balance exploration vs. exploitation\n",
    "\n",
    "### 3. BayesianOptimization\n",
    "- **How it works**: Builds a probability model of the objective function and uses it to select hyperparameters\n",
    "- **Pros**: More efficient use of resources, learns from previous evaluations\n",
    "- **Cons**: More complex, computationally intensive for each iteration\n",
    "- **Best for**: When evaluation is expensive and you have a moderate search space\n",
    "\n",
    "### 4. Sklearn\n",
    "- **How it works**: Interface to scikit-learn's hyperparameter search methods\n",
    "- **Pros**: Familiar API for those coming from scikit-learn\n",
    "- **Cons**: Limited to sklearn's hyperparameter tuning capabilities\n",
    "- **Best for**: When integrating with existing sklearn pipelines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e7af43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f47d1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kerastuner as kt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e9b048",
   "metadata": {},
   "source": [
    "Hyperparameters are of two types:\n",
    "1. **Model hyperparameters** like number of units, type of activation or number hidden layers.\n",
    "2. **Algorithm hyperparameters** like the learning rate in adam.\n",
    "\n",
    "The model-building function takes an argument `hp` from which you can sample hyper-parameters.\n",
    "\n",
    "```python\n",
    "def build_model(hp):\n",
    "    ...\n",
    "    return model\n",
    "\n",
    "```\n",
    "\n",
    "- `hp.Int` to sample an integer from a certain range:\n",
    "```python\n",
    "hp.Int('units', min_value=32, max_value=256, step=32, default=64)\n",
    "```\n",
    "- `hp.Float` to sample a float number from a certain range:\n",
    "```python\n",
    "hp.Float('dropout', min_value=0.0, max_value=0.1, default=0.005, step=0.05)\n",
    "```\n",
    "- `hp.Choice` to select values in a list:\n",
    "```python\n",
    "hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])\n",
    "```\n",
    "- [list of hyperparameter methods](https://keras-team.github.io/keras-tuner/documentation/hyperparameters/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef99c2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    # Sample different number of layers with hp.Int\n",
    "    for i in range(hp.Int('num_layers', 1, 3)):\n",
    "        # Sample different number of layers with hp.Int\n",
    "        model.add(layers.Dense(units=hp.Int('units_' + str(i),\n",
    "                                            min_value=64,\n",
    "                                            max_value=128,\n",
    "                                            step=32),\n",
    "                               activation='relu'))\n",
    "    # Sample different activation functions with hp.Choice \n",
    "    model.add(layers.Dense(1, activation=hp.Choice('output_activation', ['relu', 'linear'])))\n",
    "    \n",
    "    # Sample different activation functions with hp.Choice \n",
    "    model.compile(\n",
    "        loss='mse',\n",
    "        metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71047eeb",
   "metadata": {},
   "source": [
    "The Keras Tuner has four [tuners](https://keras-team.github.io/keras-tuner/documentation/tuners/) available  `RandomSearch`, `Hyperband`, `BayesianOptimization`, and `Sklearn`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8261f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(build_model,\n",
    "                     objective='val_loss',\n",
    "                     max_epochs=15,\n",
    "                     factor=3,\n",
    "                     hyperband_iterations=1,\n",
    "                     directory='my_dir',\n",
    "                     project_name='intro_to_kt')\n",
    "'''\n",
    "tuner = kt.RandomSearch(build_model,\n",
    "                     objective='val_loss',\n",
    "                     max_trials=100,\n",
    "                     directory='my_dir',\n",
    "                     project_name='intro_to_kt')\n",
    "'''\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322e674d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(X_train_norm, y_train, epochs=30, validation_split=0.15, batch_size=32, callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(best_hps.get_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df6dcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d31a650",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best output activation function: {best_hps.get('output_activation')}\")\n",
    "print(f\"Best number of hidden layers: {best_hps.get('num_layers')}\")\n",
    "for i in range(best_hps.get('num_layers')):\n",
    "    print(f\"Number of units of hidden layer {i+1}: {best_hps.get('units_' + str(i))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bc610d",
   "metadata": {},
   "source": [
    "### Hyperparameter Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f740b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import seaborn as sns\n",
    "\n",
    "def analyze_hyperparameter_importance(tuner, top_n=10):\n",
    "    \"\"\"\n",
    "    Analyze the importance of different hyperparameters using Random Forest.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    tuner : keras_tuner.Tuner\n",
    "        The tuner object after running a hyperparameter search\n",
    "    top_n : int, default=10\n",
    "        Number of top trials to print\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    importance_df : pandas.DataFrame\n",
    "        DataFrame containing the importance of each hyperparameter\n",
    "    \"\"\"\n",
    "    print(\"Extracting hyperparameter data from tuner...\")\n",
    "    \n",
    "    # Extract hyperparameters and scores from tuner\n",
    "    hp_results = []\n",
    "    \n",
    "    for trial_id, trial in tuner.oracle.trials.items():\n",
    "        if trial.score is not None:  # Only include completed trials\n",
    "            # Get hyperparameters\n",
    "            hp_values = trial.hyperparameters.values\n",
    "            # Add score (lower is better for loss)\n",
    "            hp_values['score'] = trial.score\n",
    "            hp_results.append(hp_values)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    results_df = pd.DataFrame(hp_results)\n",
    "    \n",
    "    # Show basic stats\n",
    "    print(f\"Analyzed {len(results_df)} trials\")\n",
    "    print(\"\\nTop {top_n} configurations:\".format(top_n=top_n))\n",
    "    top_configs = results_df.sort_values('score').head(top_n)\n",
    "    for i, (_, config) in enumerate(top_configs.iterrows()):\n",
    "        print(f\"\\nRank {i+1} (Score: {config['score']:.4f}):\")\n",
    "        for param, value in sorted(config.items()):\n",
    "            if param != 'score':\n",
    "                print(f\"  {param}: {value}\")\n",
    "    \n",
    "    # Prepare data for Random Forest\n",
    "    X = results_df.drop('score', axis=1)\n",
    "    \n",
    "    # Convert non-numeric columns to numeric\n",
    "    for col in X.columns:\n",
    "        if X[col].dtype == 'object':\n",
    "            # Create dummies for categorical variables\n",
    "            dummies = pd.get_dummies(X[col], prefix=col)\n",
    "            X = pd.concat([X.drop(col, axis=1), dummies], axis=1)\n",
    "    \n",
    "    y = results_df['score']\n",
    "    \n",
    "    # Train Random Forest for feature importance\n",
    "    print(\"\\nTraining Random Forest to analyze hyperparameter importance...\")\n",
    "    rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    rf.fit(X, y)\n",
    "    \n",
    "    # Get feature importance\n",
    "    importance = rf.feature_importances_\n",
    "    \n",
    "    # Create DataFrame of features and importance\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Importance': importance\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    # Plot feature importance\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x='Importance', y='Feature', data=importance_df.head(15))\n",
    "    plt.title('Hyperparameter Importance')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print importance values\n",
    "    print(\"\\nHyperparameter importance ranking:\")\n",
    "    for i, (_, row) in enumerate(importance_df.iterrows()):\n",
    "        if i < 15:  # Print top 15\n",
    "            print(f\"{i+1}. {row['Feature']}: {row['Importance']:.4f}\")\n",
    "    \n",
    "    # Analyze top feature's impact with partial dependence plot\n",
    "    top_feature = importance_df.iloc[0]['Feature']\n",
    "    if top_feature in X.columns:  # Ensure it's a numeric feature\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.scatter(X[top_feature], y, alpha=0.6)\n",
    "        plt.title(f'Impact of {top_feature} on Model Performance')\n",
    "        plt.xlabel(top_feature)\n",
    "        plt.ylabel('Score (lower is better)')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    print(\"\\nAnalysis complete. Use these insights to refine your hyperparameter search!\")\n",
    "    \n",
    "    return importance_df\n",
    "\n",
    "\n",
    "\n",
    "# After running tuner.search():\n",
    "\n",
    "# 1. Get overall importance\n",
    "importance_df = analyze_hyperparameter_importance(tuner)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df9ffad",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b439536",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(X_train_norm, y_train, epochs=50, validation_split=0.15, callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57509bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(X_test_norm, y_test, verbose=1)\n",
    "print('Test Loss: {}'.format(results[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbf5a27",
   "metadata": {},
   "source": [
    "## Question 4: Try to search with dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c7b527",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    \"\"\"Build a model with tunable architecture and dropout regularization.\"\"\"\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    # Tune the number of layers (try 1-4 layers)\n",
    "    for i in range(hp.Int('num_layers', min_value=..., max_value=...)):\n",
    "        # Tune the number of units in each layer\n",
    "        model.add(layers.Dense(\n",
    "            units=hp.Int(f'units_{i}', min_value=..., max_value=..., step=...),\n",
    "            activation=hp.Choice(f'activation_{i}', values=[...])\n",
    "        ))\n",
    "        \n",
    "        # Add dropout after the dense layer\n",
    "        # Hint: Experiment with different dropout ranges\n",
    "        model.add(layers.Dropout(\n",
    "            hp...(..., min_value=..., max_value=..., step=...)\n",
    "        ))\n",
    "    '''\n",
    "    # Output layer for regression)\n",
    "    model.add(layers.Dense(1, activation=...))\n",
    "\n",
    "    # Tune the optimizer and learning rate\n",
    "    # Hint: Try different optimizers and log-scale for learning rate\n",
    "    optimizer_choice = hp.Choice('optimizer', values=[...])\n",
    "    learning_rate = hp.Float('learning_rate', min_value=..., max_value=..., sampling=...)\n",
    "    \n",
    "    if optimizer_choice == 'adam':\n",
    "        optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    elif optimizer_choice == 'rmsprop':\n",
    "        optimizer = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "    else:\n",
    "        optimizer = ...\n",
    "    '''\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss=...,\n",
    "        metrics=[...]\n",
    "    )\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659d9de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(build_model,\n",
    "                     objective='val_loss',\n",
    "                     max_epochs=15,\n",
    "                     factor=3,\n",
    "                     hyperband_iterations=1,\n",
    "                     directory='my_dir_2',\n",
    "                     project_name='intro_to_kt')\n",
    "\n",
    "stop_early = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=...,\n",
    "    patience=...,\n",
    "    )\n",
    "tuner.search(X_train_norm, y_train, epochs=20, validation_split=0.15,\n",
    "             batch_size=32, callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(best_hps.get_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb414e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best learning rate: {best_hps.get('learning_rate')}\")\n",
    "print(f\"Best output activation function: {best_hps.get('output_activation')}\")\n",
    "print(f\"Best number of hidden layers: {best_hps.get('num_layers')}\")\n",
    "for i in range(best_hps.get('num_layers')):\n",
    "    print(f\"Number of units of hidden layer {i+1}: {best_hps.get('units_' + str(i))}\")\n",
    "    #print(f\"Dropout rate of hidden layer {i+1}: {best_hps.get('dp_' + str(i))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef4f3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(X_train_norm, y_train, epochs=50, validation_split=0.15, callbacks=[stop_early])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f46fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(X_test_norm, y_test, verbose=1)\n",
    "print('Test Loss: {}'.format(results[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "demo-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
